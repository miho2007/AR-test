<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AR.js Stereoscopic VR - Less Zoomed In</title>
<style>
html, body { margin: 0; width: 100%; height: 100%; overflow: hidden; background: black; }
#cameraFeed { display: none; }
.vr-container { display: flex; width: 100%; height: 100%; position: absolute; top: 0; left: 0; }
.vr-eye { width: 50%; height: 100%; overflow: hidden; }
canvas { width: 100%; height: 100%; display: block; }
</style>

<script src="https://cdn.jsdelivr.net/npm/three@0.117.1/build/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js@3.3.2/three.js/build/ar-threex.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@ar-js-org/ar.js-threejs@0.3.2/dist/ar.min.js"></script>

</head>
<body>

<video id="cameraFeed" autoplay playsinline muted></video>

<div class="vr-container">
  <canvas id="leftEye"></canvas>
  <canvas id="rightEye"></canvas>
</div>

<script>
(async function() {
  const video = document.getElementById('cameraFeed');
  let stream;

  // Start camera
  try {
    stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" }, audio: false });
  } catch(e) {
    console.warn("Back camera failed, using default camera:", e);
    stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
  }
  video.srcObject = stream;
  await video.play();
  console.log("Camera started successfully");

  // AR.js source
  const arSource = new THREEx.ArToolkitSource({ sourceType: 'webcam' });
  arSource.domElement = video;
  arSource.init(() => onResize());

  // AR.js context
  const arContext = new THREEx.ArToolkitContext({
    cameraParametersUrl: './camera_para.dat',
    detectionMode: 'mono'
  });
  await new Promise(res => arContext.init(res));

  // Hidden WebGL renderer
  const mainCanvas = document.createElement('canvas');
  const mainRenderer = new THREE.WebGLRenderer({ canvas: mainCanvas, alpha: true, antialias: true });
  mainRenderer.setSize(window.innerWidth, window.innerHeight);
  mainRenderer.setClearColor(0x000000, 0);

  const scene = new THREE.Scene();
  const camera = new THREE.PerspectiveCamera(90, window.innerWidth / window.innerHeight, 0.1, 1000); // FOV increased to 80Â°
  scene.add(camera);
  if (arContext.arController) camera.projectionMatrix.copy(arContext.getProjectionMatrix());

  // AR marker
  const markerRoot = new THREE.Group();
  scene.add(markerRoot);
  new THREEx.ArMarkerControls(arContext, markerRoot, {
    type: 'pattern',
    patternUrl: './patt.hiro'
  });

  // Video background plane
  const videoTexture = new THREE.VideoTexture(video);
  videoTexture.minFilter = THREE.LinearFilter;
  videoTexture.magFilter = THREE.LinearFilter;
  videoTexture.format = THREE.RGBFormat;
  const planeGeometry = new THREE.PlaneGeometry(16, 9);
  const planeMaterial = new THREE.MeshBasicMaterial({ map: videoTexture });
  const backgroundPlane = new THREE.Mesh(planeGeometry, planeMaterial);
  backgroundPlane.position.z = -5;
  scene.add(backgroundPlane);

  // Target (ring)
  const targetGroup = new THREE.Group();
  const colors = [0xff0000, 0xffffff, 0xff0000, 0xffffff];
  for (let i = 0; i < colors.length; i++) {
    const radiusOuter = 0.5 - i*0.1;
    const radiusInner = radiusOuter - 0.1;
    const geometry = new THREE.RingGeometry(radiusInner, radiusOuter, 32);
    const material = new THREE.MeshBasicMaterial({ color: colors[i], side: THREE.DoubleSide });
    const ring = new THREE.Mesh(geometry, material);
    ring.rotation.x = -Math.PI/2;
    targetGroup.add(ring);
  }
  targetGroup.position.set(0, 0.5, 0);
  markerRoot.add(targetGroup);

  const clock = new THREE.Clock();
  const leftCanvas = document.getElementById('leftEye');
  const rightCanvas = document.getElementById('rightEye');
  const leftCtx = leftCanvas.getContext('2d', { willReadFrequently: true });
  const rightCtx = rightCanvas.getContext('2d', { willReadFrequently: true });

  // Render loop with stereo offset
  function render() {
    const delta = clock.getDelta();
    if (arSource.ready) arContext.update(arSource.domElement);

    // Smooth rotation
    targetGroup.rotation.y += delta * 1.5;

    mainRenderer.render(scene, camera);

    const offset = -5; // pixels for stereo convergence
    const w = leftCanvas.width;
    const h = leftCanvas.height;

    leftCtx.clearRect(0, 0, w, h);
    leftCtx.drawImage(mainCanvas, -offset, 0, mainCanvas.width, mainCanvas.height);

    rightCtx.clearRect(0, 0, w, h);
    rightCtx.drawImage(mainCanvas, offset, 0, mainCanvas.width, mainCanvas.height);

    requestAnimationFrame(render);
  }
  render();

  // Responsive resize
  function onResize() {
    arSource.onResizeElement();
    const w = window.innerWidth / 2;
    const h = window.innerHeight;
    leftCanvas.width = rightCanvas.width = w;
    leftCanvas.height = rightCanvas.height = h;
    mainRenderer.setSize(window.innerWidth, window.innerHeight);
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
  }
  window.addEventListener('resize', onResize);
  onResize();

})();
</script>
</body>
</html>
