<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AR.js + Three.js Dual Eye VR</title>

<style>
  html, body {
    margin: 0; width: 100%; height: 100%;
    overflow: hidden; background: black;
  }
  #cameraFeed {
    position: absolute;
    top: 0; left: 0; width: 100%; height: 100%;
    object-fit: cover;
    z-index: 0;
  }
  .vr-container {
    display: flex;
    width: 100%; height: 100%;
    position: absolute;
    top: 0; left: 0;
    z-index: 1;
    pointer-events: none;
  }
  .vr-eye {
    width: 50%; height: 100%;
    overflow: hidden;
    position: relative;
  }
  canvas {
    width: 100%; height: 100%;
    display: block;
  }
</style>

<script src="https://threejs.org/build/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/three.js/build/ar-threex.js"></script>
</head>
<body>

<video id="cameraFeed" autoplay playsinline muted></video>

<div class="vr-container">
  <div class="vr-eye"><canvas id="leftEye"></canvas></div>
  <div class="vr-eye"><canvas id="rightEye"></canvas></div>
</div>

<script>
(async function () {
  // Camera feed
  const video = document.getElementById('cameraFeed');
  const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
  video.srcObject = stream;
  await video.play();

  // Setup for each eye
  const setupEye = (canvas) => {
    const renderer = new THREE.WebGLRenderer({ canvas, alpha: true });
    renderer.setSize(window.innerWidth / 2, window.innerHeight);
    renderer.setClearColor(0x000000, 0);

    const scene = new THREE.Scene();

    // AR.js source and context
    const arSource = new THREEx.ArToolkitSource({ sourceType: 'webcam', sourceWidth: 640, sourceHeight: 480 });
    arSource.init(() => setTimeout(() => arContext.arController && arSource.onResizeElement(), 200));

    const arContext = new THREEx.ArToolkitContext({
      cameraParametersUrl: 'https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/three.js/data/data/camera_para.dat',
      detectionMode: 'mono'
    });

    arContext.init(() => {
      camera.projectionMatrix.copy(arContext.getProjectionMatrix());
    });

    const camera = new THREE.Camera();
    scene.add(camera);

    // Marker
    const markerRoot = new THREE.Group();
    scene.add(markerRoot);
    const markerControls = new THREEx.ArMarkerControls(arContext, markerRoot, {
      type: 'pattern',
      patternUrl: 'https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/three.js/data/data/patt.hiro',
    });

    // Rotating cube
    const geometry = new THREE.BoxGeometry(1, 1, 1);
    const material = new THREE.MeshNormalMaterial();
    const cube = new THREE.Mesh(geometry, material);
    cube.position.y = 0.5;
    markerRoot.add(cube);

    // Render loop
    const clock = new THREE.Clock();
    function render() {
      const delta = clock.getDelta();
      if (arSource.ready) arContext.update(arSource.domElement);

      cube.rotation.y += delta * 2; // rotate

      renderer.render(scene, camera);
      requestAnimationFrame(render);
    }
    render();

    window.addEventListener('resize', () => {
      renderer.setSize(window.innerWidth / 2, window.innerHeight);
    });
  };

  // Initialize left and right eyes
  setupEye(document.getElementById('leftEye'));
  setupEye(document.getElementById('rightEye'));
})();
</script>

</body>
</html>
