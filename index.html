<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AR.js + Three.js Dual Eye VR (Compatible Versions)</title>

<style>
  html, body {
    margin: 0; width: 100%; height: 100%;
    overflow: hidden; background: black;
  }
  #cameraFeed {
    position: absolute;
    top: 0; left: 0; width: 100%; height: 100%;
    object-fit: cover; z-index: 0;
  }
  .vr-container {
    display: flex;
    width: 100%; height: 100%;
    position: absolute; top: 0; left: 0;
    z-index: 1;
  }
  .vr-eye { width: 50%; height: 100%; overflow: hidden; }
  canvas { width: 100%; height: 100%; display: block; }
</style>

<!-- âœ… Correct versions -->
<script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js@3.3.2/three.js/build/ar-threex.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/0.180.0/three.tsl.js" integrity="sha512-pVsOWriwN/5X/FWYhtqqQLnD+3cm8W1YqGrNrfkKgp+GMykFl7fZ0vorWpckUlZOVIG1tNVnI3D7T8DSea5TQg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js@3.3.2/three.js/build/ar-threex.js"></script>

</head>
<body>

<video id="cameraFeed" autoplay playsinline muted></video>

<div class="vr-container">
  <div class="vr-eye"><canvas id="leftEye"></canvas></div>
  <div class="vr-eye"><canvas id="rightEye"></canvas></div>
</div>

<script>
(async function() {
  // ðŸŽ¥ Camera feed
  const video = document.getElementById('cameraFeed');
  const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } });
  video.srcObject = stream;
  await video.play();

  // ðŸ§© Shared AR source
  const arSource = new THREEx.ArToolkitSource({ sourceType: 'webcam' });
  arSource.domElement = video;
  arSource.init(() => onResize());

  // ðŸ§  Shared AR context
  const arContext = new THREEx.ArToolkitContext({
    cameraParametersUrl: 'https://cdn.jsdelivr.net/gh/AR-js-org/AR.js@3.3.2/three.js/data/data/camera_para.dat',
    detectionMode: 'mono'
  });
  await new Promise(res => arContext.init(res));

  // ðŸ§± Eye setup
  function setupEye(canvas) {
    const renderer = new THREE.WebGLRenderer({ canvas, alpha: true, antialias: true });
    renderer.setSize(window.innerWidth / 2, window.innerHeight);
    renderer.setClearColor(0x000000, 0);

    const scene = new THREE.Scene();

    const camera = new THREE.Camera();
    scene.add(camera);
    if (arContext.arController) {
      camera.projectionMatrix.copy(arContext.getProjectionMatrix());
    }

    const markerRoot = new THREE.Group();
    scene.add(markerRoot);
    new THREEx.ArMarkerControls(arContext, markerRoot, {
      type: 'pattern',
      patternUrl: 'https://cdn.jsdelivr.net/gh/AR-js-org/AR.js@3.3.2/three.js/data/data/patt.hiro'
    });

    const geometry = new THREE.BoxGeometry(1, 1, 1);
    const material = new THREE.MeshNormalMaterial();
    const cube = new THREE.Mesh(geometry, material);
    cube.position.set(0, 0.5, 0);
    markerRoot.add(cube);

    const light = new THREE.DirectionalLight(0xffffff, 1);
    light.position.set(1, 2, 2);
    scene.add(light);

    const clock = new THREE.Clock();
    function render() {
      const delta = clock.getDelta();
      if (arSource.ready) {
        arContext.update(arSource.domElement);
        camera.visible = camera.visible && markerRoot.visible;
      }
      cube.rotation.y += delta * 1.5;
      renderer.render(scene, camera);
      requestAnimationFrame(render);
    }
    render();

    return renderer;
  }

  const leftRenderer = setupEye(document.getElementById('leftEye'));
  const rightRenderer = setupEye(document.getElementById('rightEye'));

  function onResize() {
    arSource.onResizeElement();
    arSource.copyElementSizeTo(leftRenderer.domElement);
    arSource.copyElementSizeTo(rightRenderer.domElement);
  }
  window.addEventListener('resize', onResize);
})();
</script>
</body>
</html>
