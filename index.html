<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AR.js Dual Eye VR Fully Working</title>
<style>
html, body { margin: 0; width: 100%; height: 100%; overflow: hidden; background: black; }
#cameraFeed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; z-index: 0; }
.vr-container { display: flex; width: 100%; height: 100%; position: absolute; top: 0; left: 0; z-index: 1; }
.vr-eye { width: 50%; height: 100%; overflow: hidden; }
canvas { width: 100%; height: 100%; display: block; }
</style>

<!-- Three.js + AR.js -->
<script src="https://cdn.jsdelivr.net/npm/three@0.117.1/build/three.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js@3.3.2/three.js/build/ar-threex.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@ar-js-org/ar.js-threejs@0.3.2/dist/ar.min.js"></script>

</head>
<body>

<video id="cameraFeed" autoplay playsinline muted></video>

<div class="vr-container">
  <div class="vr-eye"><canvas id="leftEye"></canvas></div>
  <div class="vr-eye"><canvas id="rightEye"></canvas></div>
</div>

<script>
(async function() {
  const video = document.getElementById('cameraFeed');
  let stream;

  // ðŸ”¹ Try back camera first, fallback to default
  try {
    stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "environment" }, audio: false });
  } catch(e) {
    console.warn("Back camera failed, using default camera:", e);
    stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
  }

  video.srcObject = stream;
  await video.play();
  console.log("Camera started successfully");

  // ðŸ”¹ AR.js source
  const arSource = new THREEx.ArToolkitSource({ sourceType: 'webcam' });
  arSource.domElement = video;
  arSource.init(() => onResize());

  // ðŸ”¹ AR.js context (correct camera_para.dat URL)
  const arContext = new THREEx.ArToolkitContext({
    cameraParametersUrl: './camera_para.dat',
    detectionMode: 'mono'
  });
  await new Promise(res => arContext.init(res));

  // ðŸ”¹ Function to setup each eye
  function setupEye(canvas) {
    const renderer = new THREE.WebGLRenderer({ canvas, alpha: true, antialias: true });
    renderer.setSize(window.innerWidth / 2, window.innerHeight);
    renderer.setClearColor(0x000000, 0);

    const scene = new THREE.Scene();
    const camera = new THREE.Camera();
    scene.add(camera);
    if (arContext.arController) camera.projectionMatrix.copy(arContext.getProjectionMatrix());

    const markerRoot = new THREE.Group();
    scene.add(markerRoot);
    new THREEx.ArMarkerControls(arContext, markerRoot, {
      type: 'pattern',
      patternUrl: './patt.hiro'
    });

    const cube = new THREE.Mesh(new THREE.BoxGeometry(1,1,1), new THREE.MeshNormalMaterial());
    cube.position.set(0,0.5,0);
    markerRoot.add(cube);

    const light = new THREE.DirectionalLight(0xffffff,1);
    light.position.set(1,2,2);
    scene.add(light);

    const clock = new THREE.Clock();
    function render() {
      const delta = clock.getDelta();
      if (arSource.ready) arContext.update(arSource.domElement);
      cube.rotation.y += delta * 1.5;
      renderer.render(scene, camera);
      requestAnimationFrame(render);
    }
    render();

    return renderer;
  }

  const leftRenderer = setupEye(document.getElementById('leftEye'));
  const rightRenderer = setupEye(document.getElementById('rightEye'));

  // ðŸ”¹ Resize handler
  function onResize() {
    arSource.onResizeElement();
    arSource.copyElementSizeTo(leftRenderer.domElement);
    arSource.copyElementSizeTo(rightRenderer.domElement);
  }
  window.addEventListener('resize', onResize);

})();
</script>
</body>
</html>
