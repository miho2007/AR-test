<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>AR.js Simulated VR</title>
<script src="https://aframe.io/releases/1.4.2/aframe.min.js"></script>
<script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/aframe/build/aframe-ar.js"></script>
<title>AR.js Double Canvas VR</title>
<style>
html, body {
  margin: 0; width: 100%; height: 100%; overflow: hidden; background: black;
}
#cameraFeed {
  position: absolute; top: 0; left: 0; width: 100%; height: 100%;
  object-fit: cover; z-index: 0;
}
.vr-container {
  display: flex; width: 100%; height: 100%; position: absolute; top: 0; left: 0; z-index: 1;
  pointer-events: none;
}
.vr-eye {
  width: 50%; height: 100%; overflow: hidden; position: relative;
}
.vr-eye.left canvas {
  transform: scaleX(-1);
}
a-scene {
  position: absolute; top: 0; left: 0; width: 200%; height: 100%; pointer-events: none; z-index: 1;
}
  html, body { margin:0; width:100%; height:100%; overflow:hidden; background:black; }
  .vr-container { display:flex; width:100%; height:100%; }
  .vr-eye { width:50%; height:100%; overflow:hidden; position:relative; }
  .vr-eye canvas { width:100%; height:100%; }
</style>
</head>
<body>

<video id="cameraFeed" autoplay playsinline muted></video>

<div class="vr-container">
  <div class="vr-eye left"></div>
  <div class="vr-eye right"></div>
  <div class="vr-eye left">
    <canvas id="leftEye"></canvas>
  </div>
  <div class="vr-eye right">
    <canvas id="rightEye"></canvas>
  </div>
</div>

<a-scene embedded vr-mode-ui="enabled: false"
         arjs="trackingMethod: best; sourceType: webcam; debugUIEnabled: false;">
  <a-marker preset="hiro">
    <a-box position="0 0.5 0" rotation="0 45 0" scale="0.5 0.5 0.5" color="red">
      <a-animation attribute="rotation" to="0 405 0" dur="3000" repeat="indefinite"></a-animation>
    </a-box>
  </a-marker>
  <a-entity camera></a-entity>
</a-scene>
<video id="cameraFeed" autoplay playsinline muted style="display:none"></video>

<script src="https://cdn.jsdelivr.net/gh/AR-js-org/AR.js/three.js/build/ar-threex.js"></script>
<script src="https://threejs.org/build/three.min.js"></script>
<script>
const video = document.getElementById('cameraFeed');
navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } })
  .then(stream => video.srcObject = stream)
  .catch(err => console.error('Camera error:', err));
</script>
(async function() {
  const video = document.getElementById('cameraFeed');
  const leftCanvas = document.getElementById('leftEye');
  const rightCanvas = document.getElementById('rightEye');
  const leftCtx = leftCanvas.getContext('2d');
  const rightCtx = rightCanvas.getContext('2d');

  // Get camera feed
  const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode:'environment' }});
  video.srcObject = stream;
  await video.play();

  // Resize canvases to match video
  leftCanvas.width = rightCanvas.width = video.videoWidth;
  leftCanvas.height = rightCanvas.height = video.videoHeight;

  // Dummy AR overlay for example (replace with actual AR.js render)
  function drawAR(ctx) {
    ctx.strokeStyle = 'red';
    ctx.lineWidth = 5;
    ctx.strokeRect(ctx.canvas.width/2 -50, ctx.canvas.height/2 -50, 100, 100);
  }

  // Render loop
  function render() {
    // Draw video to both canvases
    leftCtx.drawImage(video, 0, 0, leftCanvas.width, leftCanvas.height);
    rightCtx.drawImage(video, 0, 0, rightCanvas.width, rightCanvas.height);

    // Draw AR overlay
    drawAR(leftCtx);
    drawAR(rightCtx);

    requestAnimationFrame(render);
  }
  render();
})();
</script>
</body>
</html>
